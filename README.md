<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Awesome-Speech-Generation](#awesome-speech-generation)
  - [Papers](#papers)
    - [2022](#2022)
    - [Text-Guided](#text-guided)
    - [Image-Guided](#image-guided)
  - [Resources](#resources)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->



# Awesome-Speech-Generation

Paper, Code and Statistics for Speech Generatation. 

ðŸŒŸ represents important papers. 

## Papers

### 2022

- [AudioLM: a Language Modeling Approach to Audio Generation](https://arxiv.org/abs/2209.03143)  - *Z Borsos et al*, `arXiv 2022`



### Text-Guided

- [AudioGen: Textually Guided Audio Generation](https://arxiv.org/abs/2209.15352)  - *F Kreuk et al*, `arXiv 2022`



### Image-Guided

- [I Hear Your True Colors: Image Guided Audio Generation](https://arxiv.org/abs/2211.03089)  - *R Sheffer et al*, `arXiv 2022`



## Resources

[EnCodec: High Fidelity Neural Audio Compression](https://github.com/facebookresearch/encodec)

[SoundStream: An End-to-End Neural Audio Codec](https://github.com/wesbz/SoundStream)
